{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7343ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This file contains functions for converting a .csv dataset into the \n",
    "\t'task dict list' format used by the rest of the code. The .csv file must \n",
    "\thave a particular format, with columns like 'user_id', and outcome columns\n",
    "\tcontaining '_Label'. For an example, see the file 'example_data.csv'. \n",
    "\n",
    "\tHow to partition tasks:\n",
    "\t\t'users-as-tasks': The .csv file will be partioned such that predicting \n",
    "\t\t\tthe outcome of each user is one task.\n",
    "\t\t'labels-as-tasks': The .csv file will be partitioned such that \n",
    "\t\t\tpredicting related outcomes is each task (e.g. predicting stress\n",
    "\t\t\tis one task and predicting happiness is another)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import helperFuncs as helper\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "CODE_PATH = os.path.dirname(os.getcwd())\n",
    "sys.path.append(CODE_PATH)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datafile', type=str, default='/Your/path/here/')\n",
    "parser.add_argument('--task_type', type=str, default='users', \n",
    "\t\t\t\t\thelp=\"How to partition related tasks; can be 'users' so \"\n",
    "\t\t\t\t\t\t \"that predicting the outcome for each user is its own \"\n",
    "\t\t\t\t\t\t \"task, or 'labels', so that predicting related \"\n",
    "\t\t\t\t\t\t \"outcomes (like stress, happiness, etc) are their \"\n",
    "\t\t\t\t\t\t \"own tasks.\")\n",
    "parser.add_argument('--target_label', type=str, \n",
    "\t\t\t\t\tdefault='tomorrow_Happiness_Evening_Label',\n",
    "\t\t\t\t\thelp=\"Outcome label to predict for each user in \"\n",
    "\t\t\t\t\t\t \"users-as-tasks\")\n",
    "parser.add_argument('--group_users_on', type=str, \n",
    "\t\t\t\t\tdefault='user_id',\n",
    "\t\t\t\t\thelp=\"Name of column that indicates user or cluster ID \"\n",
    "\t\t\t\t\t\t \"for partitioning users into tasks.\")\n",
    "\n",
    "def getDatasetCoreNameAndPath(datafile):\n",
    "\tcore_name = os.path.basename(datafile)\n",
    "\tcore_name = os.path.splitext(core_name)[0]\n",
    "\tpath = os.path.splitext(datafile)[0].replace(core_name, '')\n",
    "\treturn core_name, path\n",
    "\n",
    "def getLabelTaskListFromDataset(datafile, subdivide_phys=True):\n",
    "\t\"\"\"Partitions a .csv file into a task-dict-list pickle file by separating\n",
    "\trelated labels into the different tasks.\"\"\"\n",
    "\tdf = pd.DataFrame.from_csv(datafile)\n",
    "\twanted_labels = [x for x in df.columns.values if '_Label' in x and 'tomorrow_' in x and 'Evening' in x and 'Alertness' not in x and 'Energy' not in x]\n",
    "\twanted_feats = [x for x in df.columns.values if x != 'user_id' and x != 'timestamp' and x!= 'dataset' and x!='Cluster' and '_Label' not in x]\n",
    "\n",
    "\tcore_name, data_path = getDatasetCoreNameAndPath(datafile)\n",
    "\n",
    "\tmodality_dict = getModalityDict(wanted_feats, subdivide_phys=subdivide_phys)\n",
    "\t\n",
    "\tfor dataset in ['Train','Val','Test']:\n",
    "\t\ttask_dict_list = []\n",
    "\t\tfor target_label in wanted_labels: \n",
    "\t\t\tmini_df = helper.normalizeAndFillDataDf(df, wanted_feats, [target_label], suppress_output=True)\n",
    "\t\t\tmini_df.reindex(np.random.permutation(mini_df.index))\n",
    "\t\t\t\t\n",
    "\t\t\tX,y = helper.getTensorFlowMatrixData(mini_df, wanted_feats, [target_label], dataset=dataset, single_output=True)\n",
    "\t\t\ttask_dict = dict()\n",
    "\t\t\ttask_dict['X'] = X\n",
    "\t\t\ttask_dict['Y'] = y\n",
    "\t\t\ttask_dict['Name'] = target_label\n",
    "\t\t\ttask_dict['ModalityDict'] = modality_dict\n",
    "\t\t\ttask_dict_list.append(task_dict)\n",
    "\t\tpickle.dump(task_dict_list, open(data_path + \"datasetTaskList-\" + core_name + \"_\" + dataset + \".p\",\"wb\"))\n",
    "\n",
    "def getModalityDict(wanted_feats, subdivide_phys=False):\n",
    "\tmodalities = list(set([getFeatPrefix(x, subdivide_phys=subdivide_phys) for x in wanted_feats]))\n",
    "\tmod_dict = dict()\n",
    "\tfor modality in modalities:\n",
    "\t\tmod_dict[modality] = getStartIndex(wanted_feats, modality)\n",
    "\treturn mod_dict\n",
    "\n",
    "def getStartIndex(wanted_feats, modality):\n",
    "\tfor i,s in enumerate(wanted_feats):\n",
    "\t\tif modality[0:4] == 'phys' and 'H' in modality and modality != 'physTemp':\n",
    "\t\t\tif modality + ':' in s:\n",
    "\t\t\t\treturn i\n",
    "\t\telse:\n",
    "\t\t\tif modality + '_' in s:\n",
    "\t\t\t\treturn i\n",
    "\n",
    "def getFeatPrefix(feat_name, subdivide_phys=False):\n",
    "\tidx = feat_name.find('_')\n",
    "\tprefix = feat_name[0:idx]\n",
    "\tif not subdivide_phys or prefix != 'phys':\n",
    "\t\treturn prefix\n",
    "\telse:\n",
    "\t\tidx = feat_name.find(':')\n",
    "\t\treturn feat_name[0:idx]\n",
    "\n",
    "def getUserTaskListFromDataset(datafile, target_label, suppress_output=False, \n",
    "\t\t\t\t\t\t\t   group_on='user_id', subdivide_phys=False):\n",
    "\t\"\"\"Partitions a .csv file into a task-dict-list pickle file by separating\n",
    "\tdifferent individuals (users) into the different tasks.\"\"\"\n",
    "\tdf = pd.DataFrame.from_csv(datafile)\n",
    "\twanted_feats = [x for x in df.columns.values if x != 'user_id' and x != 'timestamp' and x!= 'dataset' and x!='classifier_friendly_ppt_id' and 'Cluster' not in x and '_Label' not in x]\n",
    "\t\n",
    "\tdf = helper.normalizeAndFillDataDf(df, wanted_feats, [target_label], suppress_output=True)\n",
    "\tdf = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "\tdataset_name, datapath = getDatasetCoreNameAndPath(datafile)\n",
    "\tlabel_name = helper.getFriendlyLabelName(target_label)\n",
    "\t\n",
    "\tmodality_dict = getModalityDict(wanted_feats, subdivide_phys=subdivide_phys)\n",
    "\n",
    "\ttrain_task_dict_list = []\n",
    "\tval_task_dict_list = []\n",
    "\ttest_task_dict_list = []\n",
    "\tfor user in df[group_on].unique(): \n",
    "\t\tif not suppress_output:\n",
    "\t\t\tprint(\"Processing task\", user)\n",
    "\t\tmini_df = df[df[group_on] == user]\n",
    "\n",
    "\t\ttrain_task_dict_list.append(constructTaskDict(user, mini_df, wanted_feats, target_label, modality_dict, 'Train'))\n",
    "\t\tval_task_dict_list.append(constructTaskDict(user, mini_df, wanted_feats, target_label, modality_dict, 'Val'))\n",
    "\t\ttest_task_dict_list.append(constructTaskDict(user, mini_df, wanted_feats, target_label, modality_dict, 'Test'))\n",
    "\n",
    "\tif group_on == 'user_id':\n",
    "\t\tdataset_prefix = \"datasetUserTaskList-\"\n",
    "\telif group_on == 'Cluster':\n",
    "\t\tdataset_prefix = 'datasetClusterTasks-'\n",
    "\telse:\n",
    "\t\tdataset_prefix = group_on\n",
    "\tpickle.dump(train_task_dict_list, open(datapath + dataset_prefix + dataset_name + \"-\" + label_name + \"_Train.p\",\"wb\"))\n",
    "\tpickle.dump(val_task_dict_list, open(datapath + dataset_prefix + dataset_name + \"-\" + label_name + \"_Val.p\",\"wb\"))\n",
    "\tpickle.dump(test_task_dict_list, open(datapath + dataset_prefix + dataset_name + \"-\" + label_name + \"_Test.p\",\"wb\"))\n",
    "\n",
    "\treturn dataset_prefix + dataset_name + \"-\" + label_name\n",
    "\n",
    "def constructTaskDict(task_name, mini_df, wanted_feats, target_label, modality_dict, dataset):\n",
    "\tX,y = helper.getTensorFlowMatrixData(mini_df, wanted_feats, [target_label], dataset=dataset, single_output=True)\n",
    "\ttask_dict = dict()\n",
    "\ttask_dict['X'] = X\n",
    "\ttask_dict['Y'] = y\n",
    "\ttask_dict['Name'] = task_name\n",
    "\ttask_dict['ModalityDict'] = modality_dict\n",
    "\treturn task_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tkwargs = vars(parser.parse_args())\n",
    "\n",
    "\tif kwargs['task_type'] == 'labels':\n",
    "\t\tprint(\"Creating a label task-dict-list dataset where tasks are \"\n",
    "\t\t\t  \"predicting related outcome labels.\")\n",
    "\t\tgetLabelTaskListFromDataset(kwargs['datafile'])\n",
    "\telse:\n",
    "\t\tprint(\"Creating a user task-dict-list dataset where tasks are \"\n",
    "\t\t\t  \"predicting the outcome of each different person (user).\")\n",
    "\t\tgetUserTaskListFromDataset(kwargs['datafile'], \n",
    "\t\t\t\t\t\t\t\t   target_label=kwargs['target_label'],\n",
    "\t\t\t\t\t\t\t       group_on=kwargs['group_users_on'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpyth8",
   "language": "python",
   "name": "env_python8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
