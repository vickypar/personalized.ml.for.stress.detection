{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221100a1",
   "metadata": {},
   "source": [
    "## Format WESAD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fe4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "\n",
    "#directory for the data\n",
    "data_dir = 'WESAD/'\n",
    "\n",
    "#label sampling frequency\n",
    "LABEL_SF = 700\n",
    "\n",
    "#sampling rates for all the E4 sensors\n",
    "ACC_SF = 32\n",
    "BVP_SF = 64\n",
    "EDA_SF = 4\n",
    "TEMP_SF = 4\n",
    "#sampling frequencies in a dictionary\n",
    "SF_dict = {'ACC':ACC_SF, 'BVP':BVP_SF, 'EDA':EDA_SF, 'TEMP':TEMP_SF}\n",
    "\n",
    "#features from the E4 device\n",
    "features = ['ACC','BVP','EDA','TEMP']\n",
    "\n",
    "#relavent state labels\n",
    "baseline_label = 1\n",
    "stress_label = 2\n",
    "meditation_label = 4\n",
    "invalid_labels = [0, 3, 5, 6, 7] #amusement (labelled as 3) will not be used for this project\n",
    "\n",
    "def get_subject_data(subject):\n",
    "    \"\"\"\n",
    "        @brief Returns all the watch sensor data for the specified subject\n",
    "        The amusement label will be considered invalid, and meditation label\n",
    "        will be combined with the baseline label to create a non-stressed label\n",
    "        @param: subject (string): The number corresponding to the desired subject\n",
    "        @return: Returns the sensor data and labels\n",
    "    \"\"\"\n",
    "\n",
    "    #open pkl file for desired subject\n",
    "    with open(data_dir+'S'+subject+'/S'+subject+'.pkl', 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    #get the labels from the data\n",
    "    data_labels = data['label']\n",
    "    data = data['signal']['wrist']\n",
    "\n",
    "    #create window labels (the window labels are the same for all data)\n",
    "    window_labels = create_labels(data_labels, LABEL_SF)\n",
    "\n",
    "    #mask for removing invalid labels\n",
    "    mask = [x for x in range(len(window_labels)) if window_labels[x] not in invalid_labels]\n",
    "    valid_labels = window_labels[mask]\n",
    "\n",
    "    for feat in features:\n",
    "        #form into windows (and line up with labels)\n",
    "        data[feat] = create_windows(data[feat],SF_dict[feat])\n",
    "        #remove invalid labels\n",
    "        #print(mask)\n",
    "        #data[feat] = data[feat][mask] [main_list[x] for x in mask]\n",
    "        data[feat] = [data[feat][x] for x in mask]\n",
    "\n",
    "    #re-label meditation data as baseline, or non-stressed\n",
    "    med_mask = [x for x in range(len(valid_labels)) if valid_labels[x] == meditation_label]\n",
    "    valid_labels[med_mask] = baseline_label\n",
    "    #shift the labels to be 0 and 1, rather than 1 and 2 for binary crossentropy later\n",
    "    valid_labels -= 1\n",
    "    #roughly 3 times as much non-stress as stress data\n",
    "\n",
    "    #combine the data for the subject into a dictionary\n",
    "    final_data = dict()\n",
    "    final_data['data'] = {'ACC' : data['ACC'], 'BVP' : data['BVP'],\n",
    "            'EDA' : data['EDA'], 'TEMP' : data['TEMP']}\n",
    "    final_data['labels'] = valid_labels\n",
    "\n",
    "    return final_data\n",
    "\n",
    "def get_all_subjects():\n",
    "    \"\"\"\n",
    "        @breif: Gets a dictionary with the combined data for all subjects\n",
    "        @return: Returns a dictionary with the combined subject data\n",
    "    \"\"\"\n",
    "    data = {'data': {'ACC':np.empty((0,ACC_SF,3)), 'BVP':np.empty((0,BVP_SF,1)),\n",
    "            'EDA':np.empty((0,EDA_SF,1)), 'TEMP':np.empty((0,TEMP_SF,1))},\n",
    "                'labels':[]}\n",
    "\n",
    "    #gather and append all subject data\n",
    "    for x in range(2,18):\n",
    "    #subjects 1 and 12 were not included in the published data\n",
    "        if x != 12:\n",
    "            temp = get_subject_data(str(x))\n",
    "            for i in features:\n",
    "                data['data'][i] = np.append(data['data'][i],temp['data'][i],0)\n",
    "                data['labels'] = np.append(data['labels'],temp['labels'],0)\n",
    "    return data\n",
    "\n",
    "\n",
    "def norm(data):\n",
    "    \"\"\"\n",
    "        @brief Mean normalize the data (subtract mean, divide by std)\n",
    "        @param: data (list): The data to normalize\n",
    "        @return: The normalized data\n",
    "    \"\"\"\n",
    "    normalized_data = (data - np.mean(np.mean(data,0),0))/np.std(np.std(data,0),0)\n",
    "    return normalized_data\n",
    "\n",
    "def create_labels(all_labels, SF):\n",
    "    \"\"\"\n",
    "        @brief Returns the labels for the desired data in one second windows\n",
    "                overlapping 50%\n",
    "        @param: all_labels (list): The full list of labels\n",
    "        @param: SF (int): The sampling frequency of the labels\n",
    "        @return: The windowed label list for the data\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for x in range(0, len(all_labels) - SF//2, SF//2):\n",
    "        labels.append(all_labels[x])\n",
    "    return np.array(labels)\n",
    "\n",
    "def create_windows(data, data_SF, window_size=1):\n",
    "    \"\"\"\n",
    "        @brief Divide the data into one second windows with 50% overlap\n",
    "        The rounded average of the label values will be used as the window label\n",
    "        @param: data (list): The data to divide\n",
    "        @param: data_SF (int): The sampling frequency of the data\n",
    "        @param: window_size (int): The number of seconds in each window\n",
    "        @return: The windowed data and labels\n",
    "    \"\"\"\n",
    "    data_windows = []\n",
    "    for x in range(0, len(data) - window_size * (data_SF//2), window_size * (data_SF//2)):\n",
    "        data_windows.append(data[x : window_size * data_SF + x])\n",
    "\n",
    "    return data_windows\n",
    "\n",
    "def save_data(path, data):\n",
    "    \"\"\"\n",
    "        @brief Save the data to the given path\n",
    "        @param: path (string): The path for the saved data\n",
    "        @param: data (list, array, tuple, etc): The data to save\n",
    "    \"\"\"\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def save_formatted_data(path):\n",
    "    \"\"\"\n",
    "        @brief format and save the data for all subjects\n",
    "        @param: path (String): Folder to save data to (ending with a /)\n",
    "    \"\"\"\n",
    "    data = {'data': {'ACC':np.empty((0,ACC_SF,3)), 'BVP':np.empty((0,BVP_SF,1)),\n",
    "            'EDA':np.empty((0,EDA_SF,1)), 'TEMP':np.empty((0,TEMP_SF,1))},\n",
    "                'labels':[], 'id':[]}\n",
    "    for x in range(2, 18):\n",
    "        #subjects 1 and 12 were not included in the published data\n",
    "        if x != 12:\n",
    "            cur = get_subject_data(str(x))\n",
    "\n",
    "            #normalize the data here to avoid normalization with statistical data\n",
    "            for i in features:\n",
    "                cur['data'][i] = norm(cur['data'][i])\n",
    "\n",
    "            #save the data for the individual\n",
    "            save_data(path+'S'+str(x)+'.pkl', cur)\n",
    "            #append the subject data to the combined data\n",
    "            for i in features:\n",
    "                data['data'][i] = np.append(data['data'][i], cur['data'][i],0)\n",
    "            data['labels'] = np.append(data['labels'], cur['labels'],0)\n",
    "            data['id'] = np.append(data['id'], np.full(cur['labels'].size, str(x)), 0)\n",
    "    #save combined data\n",
    "    save_data(path+'All_ID.pkl', data)\n",
    "\n",
    "def save_statistics(path):\n",
    "    \"\"\"\n",
    "        @breif save statistical analysis of each time step for combined\n",
    "            and individual subjects\n",
    "        @param: path (string): Folder to save data to (ending with a /)\n",
    "    \"\"\"\n",
    "    #set up blank dictionary for the data\n",
    "    data = {'data': {'ACC':np.empty((0,8,3)), 'BVP':np.empty((0,8,1)),\n",
    "            'EDA':np.empty((0,8,1)), 'TEMP':np.empty((0,8,1))},\n",
    "                'labels':[]}\n",
    "    for x in range(2, 18):\n",
    "        #subjects 1 and 12 were not included in the published data\n",
    "        if x != 12:\n",
    "            cur = get_statistics(get_subject_data(str(x)))\n",
    "            save_data(path+'S'+str(x)+'.pkl', cur)\n",
    "\n",
    "            for i in features:\n",
    "                data['data'][i] = np.append(data['data'][i], cur['data'][i],0)\n",
    "            data['labels'] = np.append(data['labels'], cur['labels'],0)\n",
    "\n",
    "    save_data(path+'All.pkl', data)\n",
    "\n",
    "def get_statistics(data):\n",
    "    \"\"\"\n",
    "        @breif Gathers statistical values for the data, these include:\n",
    "            mean, median, minimum, maximum, standard deviation, skew,\n",
    "            kurtosis, and interquartile range\n",
    "        @param data (dictionary): The data to do analysis on\n",
    "        @return A new array with statistical values for each timestep\n",
    "    \"\"\"\n",
    "    #storage for returning\n",
    "    temp = {'data':{'ACC':[],'BVP':[],'EDA':[],'TEMP':[]}, 'labels':[]}\n",
    "    #replace each timestep with statistical analysis\n",
    "    for x in data['data']:\n",
    "        #transpose to put each timestep as the first axis\n",
    "        temp['data'][x] = np.transpose([np.mean(data['data'][x],1),\n",
    "            np.median(data['data'][x],1), np.amin(data['data'][x],1),\n",
    "            np.amax(data['data'][x],1), np.std(data['data'][x],1),\n",
    "            stats.skew(data['data'][x],1), stats.kurtosis(data['data'][x],1),\n",
    "            stats.iqr(data['data'][x],1)], axes=(1,0,2))\n",
    "    temp['labels'] = data['labels']\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd51f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_formatted_data(\"WESAD/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9e76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_statistics(\"WESAD_statistics/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dab9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WESAD_formatted/All.pkl', 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e88dce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle('WESAD/All_ID.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9678736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78766"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_testing('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a355205",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = load_file('WESAD_statisticsAll.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['signal']['wrist']['ACC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de15252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'ACC': array([[[  126.32624263, -1012.3755119 ,  1296.16359523],\n",
       "          [  233.10128359,  -738.13483315,   636.76661552],\n",
       "          [  411.0596852 ,  -738.13483315,  1024.64719182],\n",
       "          ...,\n",
       "          [  138.19013607,  -772.414918  ,  1024.64719182],\n",
       "          [   78.87066887,  -772.414918  ,  1024.64719182],\n",
       "          [   67.00677543,  -601.01449378,  1218.58747997]],\n",
       "  \n",
       "         [[   90.73456231,  -669.57466347,   636.76661552],\n",
       "          [   78.87066887,  -635.29457863,   636.76661552],\n",
       "          [  114.46234919,  -601.01449378,   753.13078841],\n",
       "          ...,\n",
       "          [  -16.04047865,  -635.29457863,  1179.79942234],\n",
       "          [  -16.04047865,  -601.01449378,  1141.01136471],\n",
       "          [  -27.90437209,  -635.29457863,  1218.58747997]],\n",
       "  \n",
       "         [[  -27.90437209,  -498.17423926,  1218.58747997],\n",
       "          [  -63.49605241,  -498.17423926,  1179.79942234],\n",
       "          [  -27.90437209,  -498.17423926,  1102.22330708],\n",
       "          ...,\n",
       "          [  -27.90437209,  -669.57466347,  1218.58747997],\n",
       "          [  -27.90437209,  -635.29457863,  1218.58747997],\n",
       "          [  -27.90437209,  -635.29457863,  1218.58747997]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          ...,\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116]],\n",
       "  \n",
       "         [[   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          ...,\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116]],\n",
       "  \n",
       "         [[   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          ...,\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116],\n",
       "          [   57.65252751,   918.94055149,   887.25155116]]]),\n",
       "  'BVP': array([[[ 13.5708015 ],\n",
       "          [ 13.1440063 ],\n",
       "          [ 13.03286172],\n",
       "          ...,\n",
       "          [-91.53640896],\n",
       "          [-71.45035969],\n",
       "          [-54.01399731]],\n",
       "  \n",
       "         [[ 41.93045363],\n",
       "          [ 42.3928151 ],\n",
       "          [ 40.00542943],\n",
       "          ...,\n",
       "          [ 23.84945266],\n",
       "          [ 23.1959225 ],\n",
       "          [ 21.51541639]],\n",
       "  \n",
       "         [[-39.92975559],\n",
       "          [-28.53521281],\n",
       "          [-18.92342916],\n",
       "          ...,\n",
       "          [ 27.3127179 ],\n",
       "          [ 22.71133211],\n",
       "          [ 13.43298222]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[  5.41429826],\n",
       "          [  3.70627653],\n",
       "          [  2.11212292],\n",
       "          ...,\n",
       "          [  9.52620242],\n",
       "          [  8.86829775],\n",
       "          [  8.04591692]],\n",
       "  \n",
       "         [[  2.02355883],\n",
       "          [  5.03473787],\n",
       "          [  7.3374042 ],\n",
       "          ...,\n",
       "          [  4.90821775],\n",
       "          [  7.35005622],\n",
       "          [  9.45029034]],\n",
       "  \n",
       "         [[  6.97049583],\n",
       "          [  5.5534704 ],\n",
       "          [  3.83279666],\n",
       "          ...,\n",
       "          [ -4.3404036 ],\n",
       "          [ -5.83334111],\n",
       "          [ -7.4021907 ]]]),\n",
       "  'EDA': array([[[ 5452.45036511],\n",
       "          [ 5366.84684757],\n",
       "          [ 5264.12262651],\n",
       "          [ 5115.74616534]],\n",
       "  \n",
       "         [[ 5264.12262651],\n",
       "          [ 5115.74616534],\n",
       "          [ 5127.15699843],\n",
       "          [ 5013.02194429]],\n",
       "  \n",
       "         [[ 5127.15699843],\n",
       "          [ 5013.02194429],\n",
       "          [ 5372.55671799],\n",
       "          [ 5235.59108991]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-1141.51599081],\n",
       "          [-1141.51599081],\n",
       "          [-1136.58907948],\n",
       "          [-1151.36596433]],\n",
       "  \n",
       "         [[-1136.58907948],\n",
       "          [-1151.36596433],\n",
       "          [-1141.51599081],\n",
       "          [-1141.51599081]],\n",
       "  \n",
       "         [[-1141.51599081],\n",
       "          [-1141.51599081],\n",
       "          [-1136.58907948],\n",
       "          [-1151.36596433]]]),\n",
       "  'TEMP': array([[[ 10279.72209064],\n",
       "          [ 10279.72209064],\n",
       "          [ 10279.72209064],\n",
       "          [ 10279.72209064]],\n",
       "  \n",
       "         [[ 10279.72209064],\n",
       "          [ 10279.72209064],\n",
       "          [ 10279.72209064],\n",
       "          [ 10279.72209064]],\n",
       "  \n",
       "         [[ 10279.72209064],\n",
       "          [ 10279.72209064],\n",
       "          [ 10279.72209064],\n",
       "          [ 10279.72209064]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-11802.68311157],\n",
       "          [-11802.68311157],\n",
       "          [-11802.68311157],\n",
       "          [-11802.68311157]],\n",
       "  \n",
       "         [[-11802.68311157],\n",
       "          [-11802.68311157],\n",
       "          [-11802.68311157],\n",
       "          [-11412.91762831]],\n",
       "  \n",
       "         [[-11802.68311157],\n",
       "          [-11412.91762831],\n",
       "          [-11412.91762831],\n",
       "          [-11412.91762831]]])},\n",
       " 'labels': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 'id': array(['2', '2', '2', ..., '17', '17', '17'], dtype='<U32')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae0fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
